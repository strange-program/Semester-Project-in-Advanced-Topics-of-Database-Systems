{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3e230d-e6d9-41b3-b1e6-7d7a0fd4593d",
   "metadata": {},
   "source": [
    "# QUERY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb086a-7c7b-4b8a-aaa3-5b598be86ebf",
   "metadata": {},
   "source": [
    "## SQL implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a76aa66-79ae-4b27-b53e-01dfc810b6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1805</td><td>application_1765289937462_1789</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1789/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1789_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1807</td><td>application_1765289937462_1791</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1791/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1791_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1808</td><td>application_1765289937462_1792</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1792/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1792_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1809</td><td>None</td><td>pyspark</td><td>starting</td><td></td><td></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8be720-a9d6-4926-aab0-0bd88b509a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1810</td><td>application_1765289937462_1794</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1794/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1794_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168624b184b94f1ea3a16b24fd2eed1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddea4a5d1a64ff4a24b3e15b47f2799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "\n",
    "# Define the data schemas\n",
    "crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "re_codes_schema = StructType([\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Vict Descent Full\", StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb549d2-2905-47de-9cce-d8e7a3ebec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0266bcdf0a433da54e933e99742751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+-----+\n",
      "|year|Victim Descent        |#    |%    |\n",
      "+----+----------------------+-----+-----+\n",
      "|2025|Hispanic/Latin/Mexican|34   |40.48|\n",
      "|2025|Unknown               |24   |28.57|\n",
      "|2025|White                 |13   |15.48|\n",
      "|2024|Hispanic/Latin/Mexican|28576|29.05|\n",
      "|2024|White                 |22958|23.34|\n",
      "|2024|Unknown               |19984|20.32|\n",
      "|2023|Hispanic/Latin/Mexican|69401|34.55|\n",
      "|2023|White                 |44615|22.21|\n",
      "|2023|Black                 |30504|15.19|\n",
      "|2022|Hispanic/Latin/Mexican|73111|35.64|\n",
      "|2022|White                 |46695|22.76|\n",
      "|2022|Black                 |34634|16.88|\n",
      "|2021|Hispanic/Latin/Mexican|63676|35.08|\n",
      "|2021|White                 |44523|24.53|\n",
      "|2021|Black                 |30173|16.62|\n",
      "|2020|Hispanic/Latin/Mexican|61606|35.33|\n",
      "|2020|White                 |42638|24.45|\n",
      "|2020|Black                 |28785|16.51|\n",
      "|2019|Hispanic/Latin/Mexican|72458|36.38|\n",
      "|2019|White                 |48863|24.54|\n",
      "|2019|Black                 |33157|16.65|\n",
      "|2018|Hispanic/Latin/Mexican|75958|36.42|\n",
      "|2018|White                 |52233|25.05|\n",
      "|2018|Black                 |35340|16.95|\n",
      "|2017|Hispanic/Latin/Mexican|78308|37.55|\n",
      "|2017|White                 |52744|25.29|\n",
      "|2017|Black                 |34713|16.65|\n",
      "|2016|Hispanic/Latin/Mexican|99135|38.74|\n",
      "|2016|White                 |63760|24.92|\n",
      "|2016|Black                 |42449|16.59|\n",
      "|2015|Hispanic/Latin/Mexican|55978|36.65|\n",
      "|2015|White                 |44102|28.87|\n",
      "|2015|Black                 |26510|17.35|\n",
      "|2014|Hispanic/Latin/Mexican|68763|38.42|\n",
      "|2014|White                 |47531|26.56|\n",
      "|2014|Black                 |32952|18.41|\n",
      "|2013|Hispanic/Latin/Mexican|66741|37.97|\n",
      "|2013|White                 |48453|27.57|\n",
      "|2013|Black                 |31975|18.19|\n",
      "|2012|Hispanic/Latin/Mexican|70338|38.25|\n",
      "|2012|White                 |51839|28.19|\n",
      "|2012|Black                 |33572|18.26|\n",
      "|2011|Hispanic/Latin/Mexican|70845|38.8 |\n",
      "|2011|White                 |51219|28.05|\n",
      "|2011|Black                 |32579|17.84|\n",
      "|2010|Hispanic/Latin/Mexican|73558|38.93|\n",
      "|2010|White                 |53835|28.49|\n",
      "|2010|Black                 |33937|17.96|\n",
      "+----+----------------------+-----+-----+\n",
      "\n",
      "Execution Time: 25.627448558807373 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Starting the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Loading data from the 2 crime datasets and combining them\n",
    "crime_data_1 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\",\n",
    "    header=True,\n",
    "    schema=crime_data_schema\n",
    ")\n",
    "\n",
    "crime_data_2 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\",\n",
    "    header=True,\n",
    "    schema=crime_data_schema\n",
    ")\n",
    "\n",
    "crime_data_df = crime_data_1.union(crime_data_2)\n",
    "\n",
    "# Loading the RE codes\n",
    "re_codes_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/RE_codes.csv\",\n",
    "    header=True,\n",
    "    schema=re_codes_schema\n",
    ")\n",
    "\n",
    "# Creating the SQL View \"crimes\" and \"re_codes\" from the corresponding dataframes\n",
    "crime_data_df.createOrReplaceTempView(\"crimes\")\n",
    "re_codes_df.createOrReplaceTempView(\"re_codes\")\n",
    "\n",
    "# Query 0: Adding the filed year (of occurence) to the table\n",
    "# After every query we save the resulting dataframe in an SQL View!\n",
    "query0 = \"\"\"\n",
    "            SELECT *, year(to_timestamp(`DATE OCC`, 'yyyy MMM dd hh:mm:ss a')) AS year\n",
    "            FROM crimes;\n",
    "         \"\"\"\n",
    "crime_data_query0_df = spark.sql(query0)\n",
    "crime_data_query0_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# Query 1: Grouping data by year and ethnicity\n",
    "# We exclude null data\n",
    "query1 = \"\"\"\n",
    "            SELECT year, `Vict Descent`, COUNT(*) AS Total FROM crimes \n",
    "            WHERE year IS NOT NULL AND `Vict Descent` IS NOT NULL \n",
    "            GROUP BY year, `Vict Descent`\n",
    "         \"\"\"\n",
    "crime_data_query1_df = spark.sql(query1)\n",
    "crime_data_query1_df.createOrReplaceTempView(\"crimes_grouped\")\n",
    "\n",
    "# Query 2: Partition previous result over years, then sort, take the top 3 and calculate percentage\n",
    "query2 = \"\"\"\n",
    "            SELECT year, `Vict Descent`, Total AS `#`, ROUND(100*(Total/sum),2) as `%` FROM (\n",
    "                SELECT *, ROW_NUMBER() OVER (\n",
    "                    PARTITION BY year\n",
    "                    ORDER BY Total DESC\n",
    "                ) AS rn, SUM(Total) OVER (PARTITION BY year) as sum\n",
    "                FROM crimes_grouped\n",
    "            ) AS t\n",
    "            WHERE rn <= 3;\n",
    "         \"\"\"\n",
    "crime_data_query2_df = spark.sql(query2)\n",
    "crime_data_query2_df.createOrReplaceTempView(\"crimes_grouped\")\n",
    "\n",
    "# Query 3: Joining the \"crimes_grouped\" with the \"re_codes\" view\n",
    "# in order to have the Full Victim Descent instead of the abbreviated letter\n",
    "# and ordering by year and total number of incidents\n",
    "query3 = \"\"\"\n",
    "            SELECT year, `Vict Descent Full` AS `Victim Descent`, `#`, `%`\n",
    "            FROM crimes_grouped NATURAL JOIN re_codes\n",
    "            ORDER BY year DESC, `#` DESC\n",
    "         \"\"\"\n",
    "result_df = spark.sql(query3)\n",
    "result_df.show(1000, truncate=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74bf6c-5de9-4f48-ad73-cad3f9b492af",
   "metadata": {},
   "source": [
    "## DataFrame implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd090c6-4834-4631-a234-d24aa1592bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1811</td><td>application_1765289937462_1795</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1795/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1795_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ba4948da96487f8b45ad0264f34e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1805</td><td>application_1765289937462_1789</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1789/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1789_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1807</td><td>application_1765289937462_1791</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1791/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1791_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1808</td><td>application_1765289937462_1792</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1792/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1792_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1811</td><td>application_1765289937462_1795</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1795/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1795_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr><tr><td>1812</td><td>application_1765289937462_1796</td><td>pyspark</td><td>starting</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1796/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-156.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1796_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd40cbb-016d-44c3-b1a6-f5c9827c9bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8810d2f6f54d92837292930bccb153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "\n",
    "# Define the data schemas\n",
    "crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "re_codes_schema = StructType([\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Vict Descent Full\", StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2dbc290-cca0-49b8-9bd8-efa6fb608428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d63cee046b4d0a88b9df7df932fac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+-----+\n",
      "|year|Victim Descent        |#    |%    |\n",
      "+----+----------------------+-----+-----+\n",
      "|2025|Hispanic/Latin/Mexican|34   |40.48|\n",
      "|2025|Unknown               |24   |28.57|\n",
      "|2025|White                 |13   |15.48|\n",
      "|2024|Hispanic/Latin/Mexican|28576|29.05|\n",
      "|2024|White                 |22958|23.34|\n",
      "|2024|Unknown               |19984|20.32|\n",
      "|2023|Hispanic/Latin/Mexican|69401|34.55|\n",
      "|2023|White                 |44615|22.21|\n",
      "|2023|Black                 |30504|15.19|\n",
      "|2022|Hispanic/Latin/Mexican|73111|35.64|\n",
      "|2022|White                 |46695|22.76|\n",
      "|2022|Black                 |34634|16.88|\n",
      "|2021|Hispanic/Latin/Mexican|63676|35.08|\n",
      "|2021|White                 |44523|24.53|\n",
      "|2021|Black                 |30173|16.62|\n",
      "|2020|Hispanic/Latin/Mexican|61606|35.33|\n",
      "|2020|White                 |42638|24.45|\n",
      "|2020|Black                 |28785|16.51|\n",
      "|2019|Hispanic/Latin/Mexican|72458|36.38|\n",
      "|2019|White                 |48863|24.54|\n",
      "|2019|Black                 |33157|16.65|\n",
      "|2018|Hispanic/Latin/Mexican|75958|36.42|\n",
      "|2018|White                 |52233|25.05|\n",
      "|2018|Black                 |35340|16.95|\n",
      "|2017|Hispanic/Latin/Mexican|78308|37.55|\n",
      "|2017|White                 |52744|25.29|\n",
      "|2017|Black                 |34713|16.65|\n",
      "|2016|Hispanic/Latin/Mexican|99135|38.74|\n",
      "|2016|White                 |63760|24.92|\n",
      "|2016|Black                 |42449|16.59|\n",
      "|2015|Hispanic/Latin/Mexican|55978|36.65|\n",
      "|2015|White                 |44102|28.87|\n",
      "|2015|Black                 |26510|17.35|\n",
      "|2014|Hispanic/Latin/Mexican|68763|38.42|\n",
      "|2014|White                 |47531|26.56|\n",
      "|2014|Black                 |32952|18.41|\n",
      "|2013|Hispanic/Latin/Mexican|66741|37.97|\n",
      "|2013|White                 |48453|27.57|\n",
      "|2013|Black                 |31975|18.19|\n",
      "|2012|Hispanic/Latin/Mexican|70338|38.25|\n",
      "|2012|White                 |51839|28.19|\n",
      "|2012|Black                 |33572|18.26|\n",
      "|2011|Hispanic/Latin/Mexican|70845|38.8 |\n",
      "|2011|White                 |51219|28.05|\n",
      "|2011|Black                 |32579|17.84|\n",
      "|2010|Hispanic/Latin/Mexican|73558|38.93|\n",
      "|2010|White                 |53835|28.49|\n",
      "|2010|Black                 |33937|17.96|\n",
      "+----+----------------------+-----+-----+\n",
      "\n",
      "Execution Time: 24.2682204246521 seconds"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, row_number, desc, sum, round, year, to_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "# Starting the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Loading data from the 2 crime datasets and combining them\n",
    "crime_data_1 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\",\n",
    "    header=True,\n",
    "    schema=crime_data_schema\n",
    ")\n",
    "\n",
    "crime_data_2 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\",\n",
    "    header=True,\n",
    "    schema=crime_data_schema\n",
    ")\n",
    "\n",
    "crime_data_df = crime_data_1.union(crime_data_2)\n",
    "\n",
    "# Loading the RE codes\n",
    "re_codes_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/RE_codes.csv\",\n",
    "    header=True,\n",
    "    schema=re_codes_schema\n",
    ")\n",
    "\n",
    "# Extracting year of occurence and adding it to the dataframe\n",
    "crime_data_df = crime_data_df.withColumn(\n",
    "    \"year\",\n",
    "    year(to_timestamp(col(\"DATE OCC\"), \"yyyy MMM dd hh:mm:ss a\"))\n",
    ")\n",
    "\n",
    "# Grouping by year and ethnicity\n",
    "# Then we remove the null values\n",
    "crime_data_grouped_df = crime_data_df.groupBy(col(\"year\"), col(\"Vict Descent\")).count()\n",
    "crime_data_grouped_df = crime_data_grouped_df.na.drop()\n",
    "\n",
    "# Define window for ordered descent counts per year\n",
    "rank_window = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "\n",
    "# Define a window for total per year (no ordering needed)\n",
    "total_window = Window.partitionBy(\"year\")\n",
    "\n",
    "# Add row_number and total per year\n",
    "# Then, get the top 3 rows and calculate the percent\n",
    "crime_data_ordered_df = crime_data_grouped_df.withColumn(\"rank\", row_number().over(rank_window)) \\\n",
    "                            .withColumn(\"total_count\", sum(\"count\").over(total_window)) \\\n",
    "                            .filter(col(\"rank\") <= 3) \\\n",
    "                            .withColumn(\"%\", round(100 * col(\"count\") / col(\"total_count\"), 2)) \\\n",
    "                            .withColumnRenamed(\"count\", \"#\") \\\n",
    "                            .drop(\"rank\") \\\n",
    "                            .drop(\"total_count\")\n",
    "\n",
    "# Renaming\n",
    "result_df = crime_data_ordered_df.join(re_codes_df, \"Vict Descent\") \\\n",
    "                .drop(\"Vict Descent\") \\\n",
    "                .withColumnRenamed(\"Vict Descent Full\", \"Victim Descent\") \\\n",
    "                .select(\"year\", \"Victim Descent\", \"#\", \"%\") \\\n",
    "                .orderBy(desc(\"year\"), desc(\"#\"))\n",
    "\n",
    "result_df.show(1000, truncate=False)\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
