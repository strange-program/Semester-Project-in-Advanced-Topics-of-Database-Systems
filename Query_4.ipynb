{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c423791-8cca-4663-98a1-4323404f88aa",
   "metadata": {},
   "source": [
    "# Query 4: First configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5ab74d-f1be-42cd-8e6f-9eda21c72dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1778</td><td>application_1765289937462_1762</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1762/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1762_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f836304f63490a87d23bfe62f72b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1720</td><td>application_1765289937462_1704</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1704/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1704_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1769</td><td>application_1765289937462_1753</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1753/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1753_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1773</td><td>application_1765289937462_1757</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1757/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1757_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1776</td><td>application_1765289937462_1760</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1760/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1760_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1777</td><td>application_1765289937462_1761</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1761/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-251.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1761_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1778</td><td>application_1765289937462_1762</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1762/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1762_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1db1dc9-d37b-4ac5-8a79-9573f3996372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614201abeed74f3a9b9f5b61f8cb93d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "# Initialize sedona context\n",
    "sedona = SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a56f396a-a8e1-44ba-a5a9-879e572d1c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e961521b84b427b91b77d2855d8ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, row_number, desc\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "police_station_schema = StructType([\n",
    "    StructField(\"X\", DoubleType()),\n",
    "    StructField(\"Y\", DoubleType()),\n",
    "    StructField(\"FID\", IntegerType()),\n",
    "    StructField(\"Division\", StringType()),\n",
    "    StructField(\"Location\", StringType()),\n",
    "    StructField(\"PREC\", IntegerType()),\n",
    "])\n",
    "\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Descent\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8373bd4-673f-4195-b530-5a7477133117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0cffde582746fe98a8e33560d7493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------+\n",
      "|        Division|average_distance| count|\n",
      "+----------------+----------------+------+\n",
      "|       HOLLYWOOD|            2.07|224124|\n",
      "|        VAN NUYS|            2.94|208129|\n",
      "|       SOUTHWEST|            2.19|189119|\n",
      "|        WILSHIRE|            2.59|186383|\n",
      "|     77TH STREET|            1.72|170620|\n",
      "| NORTH HOLLYWOOD|            2.64|168096|\n",
      "|         OLYMPIC|            1.73|162805|\n",
      "|         PACIFIC|            3.85|162027|\n",
      "|         CENTRAL|            0.99|154689|\n",
      "|         RAMPART|            1.53|153204|\n",
      "|       SOUTHEAST|            2.44|143803|\n",
      "|     WEST VALLEY|            3.02|136622|\n",
      "|        FOOTHILL|            4.26|132482|\n",
      "|         TOPANGA|             3.3|131054|\n",
      "|          HARBOR|             3.7|127071|\n",
      "|      HOLLENBECK|            2.68|116235|\n",
      "|WEST LOS ANGELES|            2.79|115969|\n",
      "|          NEWTON|            1.64|111392|\n",
      "|       NORTHEAST|            3.62|108243|\n",
      "|         MISSION|            3.68| 97926|\n",
      "|      DEVONSHIRE|            2.82| 77180|\n",
      "+----------------+----------------+------+\n",
      "\n",
      "Elapsed time:  38.14401078224182\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (23)\n",
      "+- Sort (22)\n",
      "   +- Exchange (21)\n",
      "      +- HashAggregate (20)\n",
      "         +- Exchange (19)\n",
      "            +- HashAggregate (18)\n",
      "               +- Project (17)\n",
      "                  +- Filter (16)\n",
      "                     +- Window (15)\n",
      "                        +- WindowGroupLimit (14)\n",
      "                           +- Sort (13)\n",
      "                              +- Exchange (12)\n",
      "                                 +- WindowGroupLimit (11)\n",
      "                                    +- Sort (10)\n",
      "                                       +- Project (9)\n",
      "                                          +- BroadcastNestedLoopJoin Inner BuildRight (8)\n",
      "                                             :- Union (5)\n",
      "                                             :  :- Filter (2)\n",
      "                                             :  :  +- Scan csv  (1)\n",
      "                                             :  +- Filter (4)\n",
      "                                             :     +- Scan csv  (3)\n",
      "                                             +- BroadcastExchange (7)\n",
      "                                                +- Scan csv  (6)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [3]: [DR_NO#36, LAT#62, LON#63]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "PushedFilters: [Or(Not(EqualTo(LON,0.0)),Not(EqualTo(LAT,0.0)))]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [3]: [DR_NO#36, LAT#62, LON#63]\n",
      "Condition : (NOT (LON#63 = 0.0) OR NOT (LAT#62 = 0.0))\n",
      "\n",
      "(3) Scan csv \n",
      "Output [3]: [DR_NO#92, LAT#118, LON#119]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "PushedFilters: [Or(Not(EqualTo(LON,0.0)),Not(EqualTo(LAT,0.0)))]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(4) Filter\n",
      "Input [3]: [DR_NO#92, LAT#118, LON#119]\n",
      "Condition : (NOT (LON#119 = 0.0) OR NOT (LAT#118 = 0.0))\n",
      "\n",
      "(5) Union\n",
      "\n",
      "(6) Scan csv \n",
      "Output [3]: [X#24, Y#25, Division#27]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv]\n",
      "ReadSchema: struct<X:double,Y:double,Division:string>\n",
      "\n",
      "(7) BroadcastExchange\n",
      "Input [3]: [X#24, Y#25, Division#27]\n",
      "Arguments: IdentityBroadcastMode, [plan_id=442]\n",
      "\n",
      "(8) BroadcastNestedLoopJoin\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(9) Project\n",
      "Output [3]: [DR_NO#36, Division#27, ( **org.apache.spark.sql.sedona_sql.expressions.ST_DistanceSphere**   / 1000.0) AS Distance#204]\n",
      "Input [6]: [DR_NO#36, LAT#62, LON#63, X#24, Y#25, Division#27]\n",
      "\n",
      "(10) Sort\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: [DR_NO#36 ASC NULLS FIRST, Distance#204 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(11) WindowGroupLimit\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: [DR_NO#36], [Distance#204 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "\n",
      "(12) Exchange\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: hashpartitioning(DR_NO#36, 1000), ENSURE_REQUIREMENTS, [plan_id=449]\n",
      "\n",
      "(13) Sort\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: [DR_NO#36 ASC NULLS FIRST, Distance#204 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(14) WindowGroupLimit\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: [DR_NO#36], [Distance#204 ASC NULLS FIRST], row_number(), 1, Final\n",
      "\n",
      "(15) Window\n",
      "Input [3]: [DR_NO#36, Division#27, Distance#204]\n",
      "Arguments: [row_number() windowspecdefinition(DR_NO#36, Distance#204 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_num#205], [DR_NO#36], [Distance#204 ASC NULLS FIRST]\n",
      "\n",
      "(16) Filter\n",
      "Input [4]: [DR_NO#36, Division#27, Distance#204, row_num#205]\n",
      "Condition : (row_num#205 = 1)\n",
      "\n",
      "(17) Project\n",
      "Output [2]: [Division#27, Distance#204]\n",
      "Input [4]: [DR_NO#36, Division#27, Distance#204, row_num#205]\n",
      "\n",
      "(18) HashAggregate\n",
      "Input [2]: [Division#27, Distance#204]\n",
      "Keys [1]: [Division#27]\n",
      "Functions [2]: [partial_avg(Distance#204), partial_count(1)]\n",
      "Aggregate Attributes [3]: [sum#225, count#226L, count#229L]\n",
      "Results [4]: [Division#27, sum#227, count#228L, count#230L]\n",
      "\n",
      "(19) Exchange\n",
      "Input [4]: [Division#27, sum#227, count#228L, count#230L]\n",
      "Arguments: hashpartitioning(Division#27, 1000), ENSURE_REQUIREMENTS, [plan_id=457]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [4]: [Division#27, sum#227, count#228L, count#230L]\n",
      "Keys [1]: [Division#27]\n",
      "Functions [2]: [avg(Distance#204), count(1)]\n",
      "Aggregate Attributes [2]: [avg(Distance#204)#211, count(1)#212L]\n",
      "Results [3]: [Division#27, round(avg(Distance#204)#211, 2) AS average_distance#209, count(1)#212L AS count#210L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [3]: [Division#27, average_distance#209, count#210L]\n",
      "Arguments: rangepartitioning(count#210L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=460]\n",
      "\n",
      "(22) Sort\n",
      "Input [3]: [Division#27, average_distance#209, count#210L]\n",
      "Arguments: [count#210L DESC NULLS LAST], true, 0\n",
      "\n",
      "(23) AdaptiveSparkPlan\n",
      "Output [3]: [Division#27, average_distance#209, count#210L]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "police_stations_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=police_station_schema)\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df = data1.union(data2)\n",
    "\n",
    "# SQL Implementation\n",
    "# Create views\n",
    "police_stations_df.createOrReplaceTempView(\"stations\")\n",
    "crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# Clear crimes in null island\n",
    "query0 = \"SELECT * FROM crimes WHERE NOT (LON=0 AND LAT=0)\"\n",
    "no_null_crime_df = spark.sql(query0)\n",
    "no_null_crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# First query: calculate distance of each crime from each station\n",
    "# then partition over crimes and find the nearest station\n",
    "query1 = \"SELECT Division, Distance FROM \\\n",
    "    (SELECT *, ROW_NUMBER() OVER (PARTITION BY DR_NO ORDER BY Distance) AS row_num FROM \\\n",
    "        (SELECT DR_NO, Division,\\\n",
    "        ST_DistanceSphere(ST_Point(LON, LAT),ST_Point(X, Y))/1000 AS Distance \\\n",
    "        FROM crimes,stations) AS res1 \\\n",
    "    ) WHERE row_num=1\"\n",
    "\n",
    "intermediate_res = spark.sql(query1)\n",
    "intermediate_res.createOrReplaceTempView(\"closest_stations\")\n",
    "\n",
    "# Second query: get average distance and total count of crimes per station\n",
    "query2 = \"SELECT Division, ROUND(AVG(Distance),2) AS average_distance, COUNT(*) AS count\\\n",
    "    FROM closest_stations GROUP BY Division ORDER BY count DESC\"\n",
    "res = spark.sql(query2)\n",
    "res.show(21)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \",end-start)\n",
    "res.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52204d8f-e073-4d3b-aaf3-9330a5a416b9",
   "metadata": {},
   "source": [
    "# Second configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def7867c-aa66-4c56-9f0b-87d3c8cbb1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1779</td><td>application_1765289937462_1763</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1763/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1763_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682926877b9d46748f6692eb06714a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '4g', 'spark.executor.cores': '2'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1720</td><td>application_1765289937462_1704</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1704/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1704_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1769</td><td>application_1765289937462_1753</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1753/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1753_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1773</td><td>application_1765289937462_1757</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1757/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1757_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1776</td><td>application_1765289937462_1760</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1760/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1760_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1777</td><td>application_1765289937462_1761</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1761/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-251.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1761_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1779</td><td>application_1765289937462_1763</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1763/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1763_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"4g\",\n",
    "        \"spark.executor.cores\": \"2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c25f78c-98f3-4977-a404-04ef6b3094e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb4efd649814c66802061cae097dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "# Initialize sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, row_number, desc\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "police_station_schema = StructType([\n",
    "    StructField(\"X\", DoubleType()),\n",
    "    StructField(\"Y\", DoubleType()),\n",
    "    StructField(\"FID\", IntegerType()),\n",
    "    StructField(\"Division\", StringType()),\n",
    "    StructField(\"Location\", StringType()),\n",
    "    StructField(\"PREC\", IntegerType()),\n",
    "])\n",
    "\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Descent\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079398c7-2b29-457f-ad6d-bc165632cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08605e9686e24af8b86dc842e04fe8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------+\n",
      "|        Division|average_distance| count|\n",
      "+----------------+----------------+------+\n",
      "|       HOLLYWOOD|            2.07|224124|\n",
      "|        VAN NUYS|            2.94|208129|\n",
      "|       SOUTHWEST|            2.19|189119|\n",
      "|        WILSHIRE|            2.59|186383|\n",
      "|     77TH STREET|            1.72|170620|\n",
      "| NORTH HOLLYWOOD|            2.64|168096|\n",
      "|         OLYMPIC|            1.73|162805|\n",
      "|         PACIFIC|            3.85|162027|\n",
      "|         CENTRAL|            0.99|154689|\n",
      "|         RAMPART|            1.53|153204|\n",
      "|       SOUTHEAST|            2.44|143803|\n",
      "|     WEST VALLEY|            3.02|136622|\n",
      "|        FOOTHILL|            4.26|132482|\n",
      "|         TOPANGA|             3.3|131054|\n",
      "|          HARBOR|             3.7|127071|\n",
      "|      HOLLENBECK|            2.68|116235|\n",
      "|WEST LOS ANGELES|            2.79|115969|\n",
      "|          NEWTON|            1.64|111392|\n",
      "|       NORTHEAST|            3.62|108243|\n",
      "|         MISSION|            3.68| 97926|\n",
      "|      DEVONSHIRE|            2.82| 77180|\n",
      "+----------------+----------------+------+\n",
      "\n",
      "Elapsed time:  35.123942375183105"
     ]
    }
   ],
   "source": [
    "spark.catalog.clearCache()\n",
    "start = time.time()\n",
    "\n",
    "police_stations_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=police_station_schema)\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df = data1.union(data2)\n",
    "\n",
    "# SQL Implementation\n",
    "# Create views\n",
    "police_stations_df.createOrReplaceTempView(\"stations\")\n",
    "crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# Clear crimes in null island\n",
    "query0 = \"SELECT * FROM crimes WHERE NOT (LON=0 AND LAT=0)\"\n",
    "no_null_crime_df = spark.sql(query0)\n",
    "no_null_crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# First query: calculate distance of each crime from each station\n",
    "# then partition over crimes and find the nearest station\n",
    "query1 = \"SELECT Division, Distance FROM \\\n",
    "    (SELECT *, ROW_NUMBER() OVER (PARTITION BY DR_NO ORDER BY Distance) AS row_num FROM \\\n",
    "        (SELECT DR_NO, Division,\\\n",
    "        ST_DistanceSphere(ST_Point(LON, LAT),ST_Point(X, Y))/1000 AS Distance \\\n",
    "        FROM crimes,stations) AS res1 \\\n",
    "    ) WHERE row_num=1\"\n",
    "\n",
    "intermediate_res = spark.sql(query1)\n",
    "intermediate_res.createOrReplaceTempView(\"closest_stations\")\n",
    "\n",
    "# Second query: get average distance and total count of crimes per station\n",
    "query2 = \"SELECT Division, ROUND(AVG(Distance),2) AS average_distance, COUNT(*) AS count\\\n",
    "    FROM closest_stations GROUP BY Division ORDER BY count DESC\"\n",
    "res = spark.sql(query2)\n",
    "res.show(21)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \",end-start)\n",
    "#res.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2e1df-c89d-4d09-8611-1a924eea7552",
   "metadata": {},
   "source": [
    "# Third Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31dcf1a-8dee-4270-8026-eb86cc693adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1780</td><td>application_1765289937462_1764</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1764/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1764_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c397211d202c430587f0b7be6d900588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '8g', 'spark.executor.cores': '4'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1720</td><td>application_1765289937462_1704</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1704/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1704_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1769</td><td>application_1765289937462_1753</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1753/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1753_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1773</td><td>application_1765289937462_1757</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1757/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1757_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1777</td><td>application_1765289937462_1761</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1761/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-251.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1761_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1780</td><td>application_1765289937462_1764</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1764/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1764_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"8g\",\n",
    "        \"spark.executor.cores\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0874965-807c-45f6-8351-7a03f6bde7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8827d364de1241a7b4b82545bbfcafe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "\n",
    "# Initialize sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, row_number, desc\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "police_station_schema = StructType([\n",
    "    StructField(\"X\", DoubleType()),\n",
    "    StructField(\"Y\", DoubleType()),\n",
    "    StructField(\"FID\", IntegerType()),\n",
    "    StructField(\"Division\", StringType()),\n",
    "    StructField(\"Location\", StringType()),\n",
    "    StructField(\"PREC\", IntegerType()),\n",
    "])\n",
    "\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Descent\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e65ad84f-a222-4d48-bf74-6b0ceff38425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b90e5be6948efa8ee37d999b880f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------+\n",
      "|        Division|average_distance| count|\n",
      "+----------------+----------------+------+\n",
      "|       HOLLYWOOD|            2.07|224124|\n",
      "|        VAN NUYS|            2.94|208129|\n",
      "|       SOUTHWEST|            2.19|189119|\n",
      "|        WILSHIRE|            2.59|186383|\n",
      "|     77TH STREET|            1.72|170620|\n",
      "| NORTH HOLLYWOOD|            2.64|168096|\n",
      "|         OLYMPIC|            1.73|162805|\n",
      "|         PACIFIC|            3.85|162027|\n",
      "|         CENTRAL|            0.99|154689|\n",
      "|         RAMPART|            1.53|153204|\n",
      "|       SOUTHEAST|            2.44|143803|\n",
      "|     WEST VALLEY|            3.02|136622|\n",
      "|        FOOTHILL|            4.26|132482|\n",
      "|         TOPANGA|             3.3|131054|\n",
      "|          HARBOR|             3.7|127071|\n",
      "|      HOLLENBECK|            2.68|116235|\n",
      "|WEST LOS ANGELES|            2.79|115969|\n",
      "|          NEWTON|            1.64|111392|\n",
      "|       NORTHEAST|            3.62|108243|\n",
      "|         MISSION|            3.68| 97926|\n",
      "|      DEVONSHIRE|            2.82| 77180|\n",
      "+----------------+----------------+------+\n",
      "\n",
      "Elapsed time:  27.898324251174927"
     ]
    }
   ],
   "source": [
    "spark.catalog.clearCache()\n",
    "start = time.time()\n",
    "\n",
    "police_stations_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=police_station_schema)\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df = data1.union(data2)\n",
    "\n",
    "# SQL Implementation\n",
    "# Create views\n",
    "police_stations_df.createOrReplaceTempView(\"stations\")\n",
    "crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# Clear crimes in null island\n",
    "query0 = \"SELECT * FROM crimes WHERE NOT (LON=0 AND LAT=0)\"\n",
    "no_null_crime_df = spark.sql(query0)\n",
    "no_null_crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# First query: calculate distance of each crime from each station\n",
    "# then partition over crimes and find the nearest station\n",
    "query1 = \"SELECT Division, Distance FROM \\\n",
    "    (SELECT *, ROW_NUMBER() OVER (PARTITION BY DR_NO ORDER BY Distance) AS row_num FROM \\\n",
    "        (SELECT DR_NO, Division,\\\n",
    "        ST_DistanceSphere(ST_Point(LON, LAT),ST_Point(X, Y))/1000 AS Distance \\\n",
    "        FROM crimes,stations) AS res1 \\\n",
    "    ) WHERE row_num=1\"\n",
    "\n",
    "intermediate_res = spark.sql(query1)\n",
    "intermediate_res.createOrReplaceTempView(\"closest_stations\")\n",
    "\n",
    "# Second query: get average distance and total count of crimes per station\n",
    "query2 = \"SELECT Division, ROUND(AVG(Distance),2) AS average_distance, COUNT(*) AS count\\\n",
    "    FROM closest_stations GROUP BY Division ORDER BY count DESC\"\n",
    "res = spark.sql(query2)\n",
    "res.show(21)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \",end-start)\n",
    "#res.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14997f-5817-466c-9360-b10cac319a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
