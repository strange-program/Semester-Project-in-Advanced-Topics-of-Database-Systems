{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8373bd4-673f-4195-b530-5a7477133117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95560683f5f4065989ee932a97357d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----------------+------+\n",
      "|        Division|     avg(Distance)|        Division| count|\n",
      "+----------------+------------------+----------------+------+\n",
      "|       HOLLYWOOD| 2073.575473968219|       HOLLYWOOD|224124|\n",
      "|        VAN NUYS| 2939.256360612656|        VAN NUYS|208129|\n",
      "|       SOUTHWEST|2191.4685251016463|       SOUTHWEST|189119|\n",
      "|        WILSHIRE| 2593.298374272885|        WILSHIRE|186383|\n",
      "|     77TH STREET| 1717.114916334095|     77TH STREET|170620|\n",
      "| NORTH HOLLYWOOD| 2642.499207526158| NORTH HOLLYWOOD|168096|\n",
      "|         OLYMPIC|1728.9319104161402|         OLYMPIC|162805|\n",
      "|         PACIFIC| 3853.497411898416|         PACIFIC|162027|\n",
      "|         CENTRAL| 993.3242673630771|         CENTRAL|154689|\n",
      "|         RAMPART|1534.2201910926965|         RAMPART|153204|\n",
      "|       SOUTHEAST| 2443.914918878561|       SOUTHEAST|143803|\n",
      "|     WEST VALLEY|3021.5716977222737|     WEST VALLEY|136622|\n",
      "|        FOOTHILL|4260.0997597283695|        FOOTHILL|132482|\n",
      "|         TOPANGA|3296.9892098973423|         TOPANGA|131054|\n",
      "|          HARBOR| 3701.717062632241|          HARBOR|127071|\n",
      "|      HOLLENBECK|333909.07968617155|      HOLLENBECK|119381|\n",
      "|WEST LOS ANGELES|2789.5214975546683|WEST LOS ANGELES|115969|\n",
      "|          NEWTON|1635.2270691078575|          NEWTON|111392|\n",
      "|       NORTHEAST|3622.9867594201955|       NORTHEAST|108243|\n",
      "|         MISSION|3676.2257891213576|         MISSION| 97926|\n",
      "|      DEVONSHIRE|2824.6514004239402|      DEVONSHIRE| 77180|\n",
      "+----------------+------------------+----------------+------+\n",
      "\n",
      "Elapsed time:  37.51222610473633\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (50)\n",
      "+- Sort (49)\n",
      "   +- Exchange (48)\n",
      "      +- SortMergeJoin Inner (47)\n",
      "         :- Sort (23)\n",
      "         :  +- HashAggregate (22)\n",
      "         :     +- Exchange (21)\n",
      "         :        +- HashAggregate (20)\n",
      "         :           +- Project (19)\n",
      "         :              +- Filter (18)\n",
      "         :                 +- Window (17)\n",
      "         :                    +- WindowGroupLimit (16)\n",
      "         :                       +- Sort (15)\n",
      "         :                          +- Exchange (14)\n",
      "         :                             +- AdaptiveSparkPlan (13)\n",
      "         :                                +- WindowGroupLimit (12)\n",
      "         :                                   +- Sort (11)\n",
      "         :                                      +- Project (10)\n",
      "         :                                         +- BroadcastNestedLoopJoin Cross BuildRight (9)\n",
      "         :                                            :- Union (5)\n",
      "         :                                            :  :- Project (2)\n",
      "         :                                            :  :  +- Scan csv  (1)\n",
      "         :                                            :  +- Project (4)\n",
      "         :                                            :     +- Scan csv  (3)\n",
      "         :                                            +- BroadcastExchange (8)\n",
      "         :                                               +- Project (7)\n",
      "         :                                                  +- Scan csv  (6)\n",
      "         +- Sort (46)\n",
      "            +- HashAggregate (45)\n",
      "               +- Exchange (44)\n",
      "                  +- HashAggregate (43)\n",
      "                     +- Project (42)\n",
      "                        +- Filter (41)\n",
      "                           +- Window (40)\n",
      "                              +- WindowGroupLimit (39)\n",
      "                                 +- Sort (38)\n",
      "                                    +- Exchange (37)\n",
      "                                       +- AdaptiveSparkPlan (36)\n",
      "                                          +- WindowGroupLimit (35)\n",
      "                                             +- Sort (34)\n",
      "                                                +- Project (33)\n",
      "                                                   +- BroadcastNestedLoopJoin Cross BuildRight (32)\n",
      "                                                      :- Union (28)\n",
      "                                                      :  :- Project (25)\n",
      "                                                      :  :  +- Scan csv  (24)\n",
      "                                                      :  +- Project (27)\n",
      "                                                      :     +- Scan csv  (26)\n",
      "                                                      +- BroadcastExchange (31)\n",
      "                                                         +- Project (30)\n",
      "                                                            +- Scan csv  (29)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [3]: [DR_NO#11822, LAT#11848, LON#11849]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(2) Project\n",
      "Output [2]: [DR_NO#11822,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#11962]\n",
      "Input [3]: [DR_NO#11822, LAT#11848, LON#11849]\n",
      "\n",
      "(3) Scan csv \n",
      "Output [3]: [DR_NO#11878, LAT#11904, LON#11905]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(4) Project\n",
      "Output [2]: [DR_NO#11878,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#12187]\n",
      "Input [3]: [DR_NO#11878, LAT#11904, LON#11905]\n",
      "\n",
      "(5) Union\n",
      "\n",
      "(6) Scan csv \n",
      "Output [3]: [X#11801, Y#11802, Division#11804]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv]\n",
      "ReadSchema: struct<X:double,Y:double,Division:string>\n",
      "\n",
      "(7) Project\n",
      "Output [2]: [Division#11804,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS station_geom#11813]\n",
      "Input [3]: [X#11801, Y#11802, Division#11804]\n",
      "\n",
      "(8) BroadcastExchange\n",
      "Input [2]: [Division#11804, station_geom#11813]\n",
      "Arguments: IdentityBroadcastMode, [plan_id=12359]\n",
      "\n",
      "(9) BroadcastNestedLoopJoin\n",
      "Join type: Cross\n",
      "Join condition: None\n",
      "\n",
      "(10) Project\n",
      "Output [3]: [DR_NO#11822, Division#11804,  **org.apache.spark.sql.sedona_sql.expressions.ST_DistanceSphere**   AS Distance#12032]\n",
      "Input [4]: [DR_NO#11822, crime_geom#11962, Division#11804, station_geom#11813]\n",
      "\n",
      "(11) Sort\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: [DR_NO#11822 ASC NULLS FIRST, Distance#12032 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(12) WindowGroupLimit\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: [DR_NO#11822], [Distance#12032 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "\n",
      "(13) AdaptiveSparkPlan\n",
      "Output [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(14) Exchange\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: hashpartitioning(DR_NO#11822, 1000), ENSURE_REQUIREMENTS, [plan_id=12483]\n",
      "\n",
      "(15) Sort\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: [DR_NO#11822 ASC NULLS FIRST, Distance#12032 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(16) WindowGroupLimit\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: [DR_NO#11822], [Distance#12032 ASC NULLS FIRST], row_number(), 1, Final\n",
      "\n",
      "(17) Window\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12032]\n",
      "Arguments: [row_number() windowspecdefinition(DR_NO#11822, Distance#12032 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS min_dist#12043], [DR_NO#11822], [Distance#12032 ASC NULLS FIRST]\n",
      "\n",
      "(18) Filter\n",
      "Input [4]: [DR_NO#11822, Division#11804, Distance#12032, min_dist#12043]\n",
      "Condition : ((min_dist#12043 <= 1) AND isnotnull(Division#11804))\n",
      "\n",
      "(19) Project\n",
      "Output [2]: [Division#11804, Distance#12032]\n",
      "Input [4]: [DR_NO#11822, Division#11804, Distance#12032, min_dist#12043]\n",
      "\n",
      "(20) HashAggregate\n",
      "Input [2]: [Division#11804, Distance#12032]\n",
      "Keys [1]: [Division#11804]\n",
      "Functions [1]: [partial_avg(Distance#12032)]\n",
      "Aggregate Attributes [2]: [sum#12155, count#12156L]\n",
      "Results [3]: [Division#11804, sum#12157, count#12158L]\n",
      "\n",
      "(21) Exchange\n",
      "Input [3]: [Division#11804, sum#12157, count#12158L]\n",
      "Arguments: hashpartitioning(Division#11804, 1000), ENSURE_REQUIREMENTS, [plan_id=12490]\n",
      "\n",
      "(22) HashAggregate\n",
      "Input [3]: [Division#11804, sum#12157, count#12158L]\n",
      "Keys [1]: [Division#11804]\n",
      "Functions [1]: [avg(Distance#12032)]\n",
      "Aggregate Attributes [1]: [avg(Distance#12032)#12059]\n",
      "Results [2]: [Division#11804, avg(Distance#12032)#12059 AS avg(Distance)#12060]\n",
      "\n",
      "(23) Sort\n",
      "Input [2]: [Division#11804, avg(Distance)#12060]\n",
      "Arguments: [Division#11804 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(24) Scan csv \n",
      "Output [3]: [DR_NO#12070, LAT#12096, LON#12097]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(25) Project\n",
      "Output [2]: [DR_NO#12070,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#11962]\n",
      "Input [3]: [DR_NO#12070, LAT#12096, LON#12097]\n",
      "\n",
      "(26) Scan csv \n",
      "Output [3]: [DR_NO#12098, LAT#12124, LON#12125]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(27) Project\n",
      "Output [2]: [DR_NO#12098,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#12188]\n",
      "Input [3]: [DR_NO#12098, LAT#12124, LON#12125]\n",
      "\n",
      "(28) Union\n",
      "\n",
      "(29) Scan csv \n",
      "Output [3]: [X#12126, Y#12127, Division#12129]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv]\n",
      "ReadSchema: struct<X:double,Y:double,Division:string>\n",
      "\n",
      "(30) Project\n",
      "Output [2]: [Division#12129,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS station_geom#11813]\n",
      "Input [3]: [X#12126, Y#12127, Division#12129]\n",
      "\n",
      "(31) BroadcastExchange\n",
      "Input [2]: [Division#12129, station_geom#11813]\n",
      "Arguments: IdentityBroadcastMode, [plan_id=12376]\n",
      "\n",
      "(32) BroadcastNestedLoopJoin\n",
      "Join type: Cross\n",
      "Join condition: None\n",
      "\n",
      "(33) Project\n",
      "Output [3]: [DR_NO#12070, Division#12129,  **org.apache.spark.sql.sedona_sql.expressions.ST_DistanceSphere**   AS Distance#12032]\n",
      "Input [4]: [DR_NO#12070, crime_geom#11962, Division#12129, station_geom#11813]\n",
      "\n",
      "(34) Sort\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: [DR_NO#12070 ASC NULLS FIRST, Distance#12032 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(35) WindowGroupLimit\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: [DR_NO#12070], [Distance#12032 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "\n",
      "(36) AdaptiveSparkPlan\n",
      "Output [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "(37) Exchange\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: hashpartitioning(DR_NO#12070, 1000), ENSURE_REQUIREMENTS, [plan_id=12494]\n",
      "\n",
      "(38) Sort\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: [DR_NO#12070 ASC NULLS FIRST, Distance#12032 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(39) WindowGroupLimit\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: [DR_NO#12070], [Distance#12032 ASC NULLS FIRST], row_number(), 1, Final\n",
      "\n",
      "(40) Window\n",
      "Input [3]: [DR_NO#12070, Division#12129, Distance#12032]\n",
      "Arguments: [row_number() windowspecdefinition(DR_NO#12070, Distance#12032 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS min_dist#12043], [DR_NO#12070], [Distance#12032 ASC NULLS FIRST]\n",
      "\n",
      "(41) Filter\n",
      "Input [4]: [DR_NO#12070, Division#12129, Distance#12032, min_dist#12043]\n",
      "Condition : ((min_dist#12043 <= 1) AND isnotnull(Division#12129))\n",
      "\n",
      "(42) Project\n",
      "Output [1]: [Division#12129]\n",
      "Input [4]: [DR_NO#12070, Division#12129, Distance#12032, min_dist#12043]\n",
      "\n",
      "(43) HashAggregate\n",
      "Input [1]: [Division#12129]\n",
      "Keys [1]: [Division#12129]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#12159L]\n",
      "Results [2]: [Division#12129, count#12160L]\n",
      "\n",
      "(44) Exchange\n",
      "Input [2]: [Division#12129, count#12160L]\n",
      "Arguments: hashpartitioning(Division#12129, 1000), ENSURE_REQUIREMENTS, [plan_id=12501]\n",
      "\n",
      "(45) HashAggregate\n",
      "Input [2]: [Division#12129, count#12160L]\n",
      "Keys [1]: [Division#12129]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#12066L]\n",
      "Results [2]: [Division#12129, count(1)#12066L AS count#12067L]\n",
      "\n",
      "(46) Sort\n",
      "Input [2]: [Division#12129, count#12067L]\n",
      "Arguments: [Division#12129 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(47) SortMergeJoin\n",
      "Left keys [1]: [Division#11804]\n",
      "Right keys [1]: [Division#12129]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(48) Exchange\n",
      "Input [4]: [Division#11804, avg(Distance)#12060, Division#12129, count#12067L]\n",
      "Arguments: rangepartitioning(count#12067L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=12505]\n",
      "\n",
      "(49) Sort\n",
      "Input [4]: [Division#11804, avg(Distance)#12060, Division#12129, count#12067L]\n",
      "Arguments: [count#12067L DESC NULLS LAST], true, 0\n",
      "\n",
      "(50) AdaptiveSparkPlan\n",
      "Output [4]: [Division#11804, avg(Distance)#12060, Division#12129, count#12067L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "+----------------+----------------+------+\n",
      "|        Division|average_distance| count|\n",
      "+----------------+----------------+------+\n",
      "|       HOLLYWOOD|         2073.58|224124|\n",
      "|        VAN NUYS|         2939.26|208129|\n",
      "|       SOUTHWEST|         2191.47|189119|\n",
      "|        WILSHIRE|          2593.3|186383|\n",
      "|     77TH STREET|         1717.11|170620|\n",
      "| NORTH HOLLYWOOD|          2642.5|168096|\n",
      "|         OLYMPIC|         1728.93|162805|\n",
      "|         PACIFIC|          3853.5|162027|\n",
      "|         CENTRAL|          993.32|154689|\n",
      "|         RAMPART|         1534.22|153204|\n",
      "|       SOUTHEAST|         2443.91|143803|\n",
      "|     WEST VALLEY|         3021.57|136622|\n",
      "|        FOOTHILL|          4260.1|132482|\n",
      "|         TOPANGA|         3296.99|131054|\n",
      "|          HARBOR|         3701.72|127071|\n",
      "|      HOLLENBECK|       333909.08|119381|\n",
      "|WEST LOS ANGELES|         2789.52|115969|\n",
      "|          NEWTON|         1635.23|111392|\n",
      "|       NORTHEAST|         3622.99|108243|\n",
      "|         MISSION|         3676.23| 97926|\n",
      "|      DEVONSHIRE|         2824.65| 77180|\n",
      "+----------------+----------------+------+\n",
      "\n",
      "Elapsed time:  22.251140356063843\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (21)\n",
      "+- Sort (20)\n",
      "   +- Exchange (19)\n",
      "      +- HashAggregate (18)\n",
      "         +- Exchange (17)\n",
      "            +- HashAggregate (16)\n",
      "               +- Project (15)\n",
      "                  +- Filter (14)\n",
      "                     +- Window (13)\n",
      "                        +- WindowGroupLimit (12)\n",
      "                           +- Sort (11)\n",
      "                              +- Exchange (10)\n",
      "                                 +- WindowGroupLimit (9)\n",
      "                                    +- Sort (8)\n",
      "                                       +- Project (7)\n",
      "                                          +- BroadcastNestedLoopJoin Inner BuildRight (6)\n",
      "                                             :- Union (3)\n",
      "                                             :  :- Scan csv  (1)\n",
      "                                             :  +- Scan csv  (2)\n",
      "                                             +- BroadcastExchange (5)\n",
      "                                                +- Scan csv  (4)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [3]: [DR_NO#11822, LAT#11848, LON#11849]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(2) Scan csv \n",
      "Output [3]: [DR_NO#11878, LAT#11904, LON#11905]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "\n",
      "(3) Union\n",
      "\n",
      "(4) Scan csv \n",
      "Output [3]: [X#11801, Y#11802, Division#11804]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv]\n",
      "ReadSchema: struct<X:double,Y:double,Division:string>\n",
      "\n",
      "(5) BroadcastExchange\n",
      "Input [3]: [X#11801, Y#11802, Division#11804]\n",
      "Arguments: IdentityBroadcastMode, [plan_id=12888]\n",
      "\n",
      "(6) BroadcastNestedLoopJoin\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [3]: [DR_NO#11822, Division#11804,  **org.apache.spark.sql.sedona_sql.expressions.ST_DistanceSphere**   AS Distance#12195]\n",
      "Input [6]: [DR_NO#11822, LAT#11848, LON#11849, X#11801, Y#11802, Division#11804]\n",
      "\n",
      "(8) Sort\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: [DR_NO#11822 ASC NULLS FIRST, Distance#12195 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(9) WindowGroupLimit\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: [DR_NO#11822], [Distance#12195 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "\n",
      "(10) Exchange\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: hashpartitioning(DR_NO#11822, 1000), ENSURE_REQUIREMENTS, [plan_id=12895]\n",
      "\n",
      "(11) Sort\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: [DR_NO#11822 ASC NULLS FIRST, Distance#12195 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(12) WindowGroupLimit\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: [DR_NO#11822], [Distance#12195 ASC NULLS FIRST], row_number(), 1, Final\n",
      "\n",
      "(13) Window\n",
      "Input [3]: [DR_NO#11822, Division#11804, Distance#12195]\n",
      "Arguments: [row_number() windowspecdefinition(DR_NO#11822, Distance#12195 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_num#12196], [DR_NO#11822], [Distance#12195 ASC NULLS FIRST]\n",
      "\n",
      "(14) Filter\n",
      "Input [4]: [DR_NO#11822, Division#11804, Distance#12195, row_num#12196]\n",
      "Condition : (row_num#12196 = 1)\n",
      "\n",
      "(15) Project\n",
      "Output [2]: [Division#11804, Distance#12195]\n",
      "Input [4]: [DR_NO#11822, Division#11804, Distance#12195, row_num#12196]\n",
      "\n",
      "(16) HashAggregate\n",
      "Input [2]: [Division#11804, Distance#12195]\n",
      "Keys [1]: [Division#11804]\n",
      "Functions [2]: [partial_avg(Distance#12195), partial_count(1)]\n",
      "Aggregate Attributes [3]: [sum#12217, count#12218L, count#12221L]\n",
      "Results [4]: [Division#11804, sum#12219, count#12220L, count#12222L]\n",
      "\n",
      "(17) Exchange\n",
      "Input [4]: [Division#11804, sum#12219, count#12220L, count#12222L]\n",
      "Arguments: hashpartitioning(Division#11804, 1000), ENSURE_REQUIREMENTS, [plan_id=12903]\n",
      "\n",
      "(18) HashAggregate\n",
      "Input [4]: [Division#11804, sum#12219, count#12220L, count#12222L]\n",
      "Keys [1]: [Division#11804]\n",
      "Functions [2]: [avg(Distance#12195), count(1)]\n",
      "Aggregate Attributes [2]: [avg(Distance#12195)#12202, count(1)#12203L]\n",
      "Results [3]: [Division#11804, round(avg(Distance#12195)#12202, 2) AS average_distance#12200, count(1)#12203L AS count#12201L]\n",
      "\n",
      "(19) Exchange\n",
      "Input [3]: [Division#11804, average_distance#12200, count#12201L]\n",
      "Arguments: rangepartitioning(count#12201L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=12906]\n",
      "\n",
      "(20) Sort\n",
      "Input [3]: [Division#11804, average_distance#12200, count#12201L]\n",
      "Arguments: [count#12201L DESC NULLS LAST], true, 0\n",
      "\n",
      "(21) AdaptiveSparkPlan\n",
      "Output [3]: [Division#11804, average_distance#12200, count#12201L]\n",
      "Arguments: isFinalPlan=false"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col, row_number, desc\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "# Initialize spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Dataframe query 1 execution (no UDF)\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize sedone context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Load police stations\n",
    "police_station_schema = StructType([\n",
    "    StructField(\"X\", DoubleType()),\n",
    "    StructField(\"Y\", DoubleType()),\n",
    "    StructField(\"FID\", IntegerType()),\n",
    "    StructField(\"Division\", StringType()),\n",
    "    StructField(\"Location\", StringType()),\n",
    "    StructField(\"PREC\", IntegerType()),\n",
    "])\n",
    "\n",
    "police_stations_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=police_station_schema)\n",
    "\n",
    "# Create geometry row for coords\n",
    "police_stations_df = police_stations_df.withColumn(\"station_geom\", ST_Point(\"X\", \"Y\"))\n",
    "\n",
    "# Load crime data\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Descent\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df = data1.union(data2)\n",
    "\n",
    "# Create geometry row for coords\n",
    "crime_df = crime_df.withColumn(\"crime_geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "\n",
    "# Start timer\n",
    "start = time.time()\n",
    "\n",
    "# Get the cartesian product of crimes x police stations\n",
    "# then compute the distance of each crime from each station\n",
    "cartesian_prod = crime_df.crossJoin(police_stations_df).select(\"DR_NO\",\"Division\",\"crime_geom\",\"station_geom\")\n",
    "cartesian_prod_with_dist = cartesian_prod.withColumn(\"Distance\",ST_DistanceSphere(\"crime_geom\",\"station_geom\")).drop(\"station_geom\")\n",
    "\n",
    "# Partition cartesian product over crimes to find the nearest station fro each\n",
    "window = Window.partitionBy(\"DR_NO\").orderBy(col(\"Distance\"))\n",
    "closest_station_df = cartesian_prod_with_dist.withColumn(\"min_dist\",row_number().over(window)).filter(col(\"min_dist\") <= 1)\n",
    "closest_station_df = closest_station_df.drop(\"min_dist\").drop(\"crime_geom\")\n",
    "\n",
    "# Get the average distance and total number of crimes per station\n",
    "avg_crimes_per_station = closest_station_df.groupBy(col(\"Division\")).avg(\"Distance\")\n",
    "tot_crimes_per_station = closest_station_df.groupBy(col(\"Division\")).count()\n",
    "\n",
    "# Join the above results to get the final one\n",
    "results = avg_crimes_per_station.join(tot_crimes_per_station, avg_crimes_per_station.Division==tot_crimes_per_station.Division)\\\n",
    "    .orderBy(desc(\"count\"))\n",
    "results.show(21)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \",end-start)\n",
    "results.explain(mode=\"formatted\")\n",
    "\n",
    "# SQL Implementation\n",
    "# Create views\n",
    "start = time.time()\n",
    "police_stations_df.createOrReplaceTempView(\"stations\")\n",
    "crime_df.createOrReplaceTempView(\"crimes\")\n",
    "\n",
    "# First query: calculate distance of each crime from each station\n",
    "# then partition over crimes and find the nearest station\n",
    "query1 = \"SELECT Division, Distance FROM \\\n",
    "    (SELECT *, ROW_NUMBER() OVER (PARTITION BY DR_NO ORDER BY Distance) AS row_num FROM \\\n",
    "        (SELECT DR_NO, Division,\\\n",
    "        ST_DistanceSphere(ST_Point(LON, LAT),ST_Point(X, Y)) AS Distance \\\n",
    "        FROM crimes,stations) AS res1 \\\n",
    "    ) WHERE row_num=1\"\n",
    "\n",
    "intermediate_res = spark.sql(query1)\n",
    "intermediate_res.createOrReplaceTempView(\"closest_stations\")\n",
    "\n",
    "# Second query: get average distance and total count of crimes per station\n",
    "query2 = \"SELECT Division, ROUND(AVG(Distance),2) AS average_distance, COUNT(*) AS count \\\n",
    "    FROM closest_stations GROUP BY Division ORDER BY count DESC\"\n",
    "res = spark.sql(query2)\n",
    "res.show(21)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \",end-start)\n",
    "res.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7867c-aa66-4c56-9f0b-87d3c8cbb1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
