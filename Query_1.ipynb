{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f909839-99dc-490f-90ac-d380c47e8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY 1\n",
    "# RDD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69f58ad3-d291-490a-9986-d9799f947ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60974507aee647f3a488864cad105698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[945] at RDD at PythonRDD.scala:55\n",
      "[['adult', 121660], ['young adult', 33758], ['child', 16014], ['senior', 6011]]"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"wordcount example\") \\\n",
    "    .getOrCreate() \\\n",
    "    .sparkContext\n",
    "\n",
    "data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "df1 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\",\n",
    "    header=False,\n",
    "    schema=data_schema,\n",
    "    quote='\"',\n",
    "    escape='\"'\n",
    ")\n",
    "\n",
    "df2 = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\",\n",
    "    header=False,\n",
    "    schema=data_schema,\n",
    "    quote='\"',\n",
    "    escape='\"'\n",
    ")\n",
    "\n",
    "data1 = df1.rdd\n",
    "data2 = df2.rdd\n",
    "data = data1.union(data2)\n",
    "\n",
    "aggravated_assaults = data.filter(lambda x: \"AGGRAVATED ASSAULT\" in x[9])\n",
    "print(aggravated_assaults)\n",
    "\n",
    "def get_age_group(x):\n",
    "    age = int(x[11])\n",
    "    if age < 18 : return [\"child\", 1]\n",
    "    elif 18<=age<=24 : return [\"young adult\", 1]\n",
    "    elif 25<=age<=64 : return [\"adult\", 1]\n",
    "    else : return [\"senior\", 1]\n",
    "\n",
    "assault_age_group = aggravated_assaults.map(get_age_group)\n",
    "age_group_count = assault_age_group.reduceByKey(lambda x,y: x+y)\n",
    "sorted_data = age_group_count.map(lambda x: [x[1] , x[0]]).sortByKey(ascending=False).map(lambda x: [x[1] , x[0]])\n",
    "\n",
    "print(sorted_data.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d5b54-9b3e-4595-8bb2-e05b549213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe implementation (no UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc769b2a-701a-4900-a1cc-66c3f71c5c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b06052be3346688a9822c20f8a64e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|   AgeGroup| Count|\n",
      "+-----------+------+\n",
      "|      adult|121660|\n",
      "|young_adult| 33758|\n",
      "|      child| 16014|\n",
      "|     senior|  6011|\n",
      "+-----------+------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, lit, count, when, expr\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Dataframe query 1 execution (no UDF)\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=data_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=data_schema)\n",
    "\n",
    "data = data1.union(data2)\n",
    "aggravated_assaults = data.filter(col(\"Crm Cd Desc\").contains(\"AGGRAVATED ASSAULT\"))\n",
    "\n",
    "\"\"\"group1 = aggravated_assaults.filter(col(\"Vict Age\")<18).count()\n",
    "group1_df = spark.createDataFrame([(group1,)]).withColumn(\"AgeGroup\", lit(\"child\")).select(\"AgeGroup\", \"_1\")\n",
    "\n",
    "group2 = aggravated_assaults.filter((col(\"Vict Age\")>=18) & (col(\"Vict Age\")<=24)).count()\n",
    "group2_df = spark.createDataFrame([(group2,)]).withColumn(\"AgeGroup\", lit(\"young_adult\")).select(\"AgeGroup\", \"_1\")\n",
    "\n",
    "group3 = aggravated_assaults.filter((col(\"Vict Age\")>=25) & (col(\"Vict Age\")<=64)).count()\n",
    "group3_df = spark.createDataFrame([(group3,)]).withColumn(\"AgeGroup\", lit(\"adult\")).select(\"AgeGroup\", \"_1\")\n",
    "\n",
    "group4 = aggravated_assaults.filter(col(\"Vict Age\")>64).count()\n",
    "group4_df = spark.createDataFrame([(group4,)]).withColumn(\"AgeGroup\", lit(\"senior\")).select(\"AgeGroup\", \"_1\")\n",
    "\n",
    "groups = group1_df.unionByName(group2_df).unionByName(group3_df).unionByName(group4_df).sort(col(\"_1\"),ascending=False)\n",
    "groups.show()\"\"\"\n",
    "\n",
    "# Count all age groups in one go\n",
    "age_group_counts = aggravated_assaults.agg(\n",
    "    count(when(col(\"Vict Age\") < 18, True)).alias(\"child\"),\n",
    "    count(when((col(\"Vict Age\") >= 18) & (col(\"Vict Age\") <= 24), True)).alias(\"young_adult\"),\n",
    "    count(when((col(\"Vict Age\") >= 25) & (col(\"Vict Age\") <= 64), True)).alias(\"adult\"),\n",
    "    count(when(col(\"Vict Age\") > 64, True)).alias(\"senior\")\n",
    ")\n",
    "\n",
    "# Convert to rows using stack and sort\n",
    "age_group_counts_melted = age_group_counts.selectExpr(\n",
    "    \"stack(4, 'child', child, 'young_adult', young_adult, 'adult', adult, 'senior', senior) as (AgeGroup, Count)\"\n",
    ").orderBy(col(\"Count\").desc())\n",
    "\n",
    "age_group_counts_melted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2e8b8-63b3-4ac5-bc3d-a1a86b096792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe implementation (with UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "938e0e40-28c2-4aef-9b6a-121d6504df48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae067959151c4cac8c6584cdb222c406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138130\n",
      "177443\n",
      "+-----------+------+\n",
      "|  age group| count|\n",
      "+-----------+------+\n",
      "|      adult|121660|\n",
      "|young adult| 33758|\n",
      "|      child| 16014|\n",
      "|     senior|  6011|\n",
      "+-----------+------+"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, DoubleType, StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Dataframe query 1 execution (with UDF)\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", IntegerType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", IntegerType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", IntegerType()),\n",
    "    StructField(\"Crm Cd 2\", IntegerType()),\n",
    "    StructField(\"Crm Cd 3\", IntegerType()),\n",
    "    StructField(\"Crm Cd 4\", IntegerType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", DoubleType()),\n",
    "    StructField(\"LON\", DoubleType()),\n",
    "])\n",
    "\n",
    "data1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=data_schema)\n",
    "\n",
    "data2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=data_schema)\n",
    "\n",
    "data = data1.union(data2)\n",
    "\n",
    "aggravated_assaults = data.filter(col(\"Crm Cd Desc\").contains(\"AGGRAVATED ASSAULT\"))\n",
    "print(aggravated_assaults.count())\n",
    "\n",
    "def get_group(x):\n",
    "    if (x<18): return \"child\"\n",
    "    elif (x>=18 and x<=24): return \"young adult\"\n",
    "    elif (x>=25 and x<=64): return \"adult\"\n",
    "    return \"senior\"\n",
    "\n",
    "get_group_udf = udf(get_group,StringType())\n",
    "\n",
    "results = aggravated_assaults.withColumn(\"age group\", get_group_udf(col(\"Vict Age\"))).groupBy(col(\"age group\")).count()\n",
    "results_sorted = results.sort(col(\"count\"),ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c856f8c-0ac4-496f-a3c8-5db4f1c6096f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
